{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensemble\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, GradientBoostingRegressor\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis, LinearDiscriminantAnalysis\n",
    "from catboost import CatBoostClassifier, CatBoostRegressor\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.metrics import silhouette_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.metrics import f1_score, accuracy_score, recall_score, precision_score, precision_recall_fscore_support\n",
    "import pandas as pd\n",
    "\n",
    "class Classification:\n",
    "    def __init__(self, data, target):\n",
    "        self.data = data\n",
    "        self.target = target\n",
    "\n",
    "    def train_test_set(self):\n",
    "        data = self.data\n",
    "        target = self.target\n",
    "        X = data.drop(target, axis=1)\n",
    "        y = data[target]\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        return X_train, X_test, y_train, y_test\n",
    "    \n",
    "    def train_val_set(self):\n",
    "        X_train, X_test, y_train, y_test = self.train_test_set()\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "        return X_train, X_val, y_train, y_val\n",
    "    \n",
    "    def rfc_train(self):\n",
    "        X_train, X_test, y_train, y_test = self.train_test_set()\n",
    "        model = RandomForestClassifier().fit(X_train, y_train)\n",
    "        train_pred = model.predict(X_train)\n",
    "        test_pred = model.predict(X_test)\n",
    "        X_train, X_val, y_train, y_val = self.train_val_set()\n",
    "        val_pred = model.predict(val_pred)\n",
    "        train_score, test_score, val_score = precision_recall_fscore_support(y_train, train_pred), precision_recall_fscore_support(y_test, test_pred), precision_recall_fscore_support(y_val, val_pred)\n",
    "        train_acc, test_acc, val_acc = accuracy_score(y_train, train_pred), accuracy_score(y_train, test_pred), accuracy_score(y_train, val_pred)\n",
    "        result = {'train_score': train_score, 'test_score': test_score, 'val_score': val_score, 'train_acc': train_acc, 'test_acc': test_acc, 'val_acc': val_acc}\n",
    "        return result\n",
    "    \n",
    "    def rfc_train(self):\n",
    "        X_train, X_test, y_train, y_test = self.train_test_set()\n",
    "        model = GradientBoostingClassifier().fit(X_train, y_train)\n",
    "        train_pred = model.predict(X_train)\n",
    "        test_pred = model.predict(X_test)\n",
    "        X_train, X_val, y_train, y_val = self.train_val_set()\n",
    "        val_pred = model.predict(val_pred)\n",
    "        train_score, test_score, val_score = precision_recall_fscore_support(y_train, train_pred), precision_recall_fscore_support(y_test, test_pred), precision_recall_fscore_support(y_val, val_pred)\n",
    "        train_acc, test_acc, val_acc = accuracy_score(y_train, train_pred), accuracy_score(y_train, test_pred), accuracy_score(y_train, val_pred)\n",
    "        result = {'train_score': train_score, 'test_score': test_score, 'val_score': val_score, 'train_acc': train_acc, 'test_acc': test_acc, 'val_acc': val_acc}\n",
    "        return result\n",
    "    \n",
    "    def rfc_train(self):\n",
    "        X_train, X_test, y_train, y_test = self.train_test_set()\n",
    "        model = XGBClassifier().fit(X_train, y_train)\n",
    "        train_pred = model.predict(X_train)\n",
    "        test_pred = model.predict(X_test)\n",
    "        X_train, X_val, y_train, y_val = self.train_val_set()\n",
    "        val_pred = model.predict(val_pred)\n",
    "        train_score, test_score, val_score = precision_recall_fscore_support(y_train, train_pred), precision_recall_fscore_support(y_test, test_pred), precision_recall_fscore_support(y_val, val_pred)\n",
    "        train_acc, test_acc, val_acc = accuracy_score(y_train, train_pred), accuracy_score(y_train, test_pred), accuracy_score(y_train, val_pred)\n",
    "        result = {'train_score': train_score, 'test_score': test_score, 'val_score': val_score, 'train_acc': train_acc, 'test_acc': test_acc, 'val_acc': val_acc}\n",
    "        return result\n",
    "\n",
    "    def rfc_train(self):\n",
    "        X_train, X_test, y_train, y_test = self.train_test_set()\n",
    "        model = KNeighborsClassifier().fit(X_train, y_train)\n",
    "        train_pred = model.predict(X_train)\n",
    "        test_pred = model.predict(X_test)\n",
    "        X_train, X_val, y_train, y_val = self.train_val_set()\n",
    "        val_pred = model.predict(val_pred)\n",
    "        train_score, test_score, val_score = precision_recall_fscore_support(y_train, train_pred), precision_recall_fscore_support(y_test, test_pred), precision_recall_fscore_support(y_val, val_pred)\n",
    "        train_acc, test_acc, val_acc = accuracy_score(y_train, train_pred), accuracy_score(y_train, test_pred), accuracy_score(y_train, val_pred)\n",
    "        result = {'train_score': train_score, 'test_score': test_score, 'val_score': val_score, 'train_acc': train_acc, 'test_acc': test_acc, 'val_acc': val_acc}\n",
    "        return result\n",
    "\n",
    "    def rfc_train(self):\n",
    "        X_train, X_test, y_train, y_test = self.train_test_set()\n",
    "        model = AdaBoostClassifier().fit(X_train, y_train)\n",
    "        train_pred = model.predict(X_train)\n",
    "        test_pred = model.predict(X_test)\n",
    "        X_train, X_val, y_train, y_val = self.train_val_set()\n",
    "        val_pred = model.predict(val_pred)\n",
    "        train_score, test_score, val_score = precision_recall_fscore_support(y_train, train_pred), precision_recall_fscore_support(y_test, test_pred), precision_recall_fscore_support(y_val, val_pred)\n",
    "        train_acc, test_acc, val_acc = accuracy_score(y_train, train_pred), accuracy_score(y_train, test_pred), accuracy_score(y_train, val_pred)\n",
    "        result = {'train_score': train_score, 'test_score': test_score, 'val_score': val_score, 'train_acc': train_acc, 'test_acc': test_acc, 'val_acc': val_acc}\n",
    "        return result\n",
    "\n",
    "    def rfc_train(self):\n",
    "        X_train, X_test, y_train, y_test = self.train_test_set()\n",
    "        model = GaussianNB().fit(X_train, y_train)\n",
    "        train_pred = model.predict(X_train)\n",
    "        test_pred = model.predict(X_test)\n",
    "        X_train, X_val, y_train, y_val = self.train_val_set()\n",
    "        val_pred = model.predict(val_pred)\n",
    "        train_score, test_score, val_score = precision_recall_fscore_support(y_train, train_pred), precision_recall_fscore_support(y_test, test_pred), precision_recall_fscore_support(y_val, val_pred)\n",
    "        train_acc, test_acc, val_acc = accuracy_score(y_train, train_pred), accuracy_score(y_train, test_pred), accuracy_score(y_train, val_pred)\n",
    "        result = {'train_score': train_score, 'test_score': test_score, 'val_score': val_score, 'train_acc': train_acc, 'test_acc': test_acc, 'val_acc': val_acc}\n",
    "        return result\n",
    "\n",
    "    def rfc_train(self):\n",
    "        X_train, X_test, y_train, y_test = self.train_test_set()\n",
    "        model = QuadraticDiscriminantAnalysis().fit(X_train, y_train)\n",
    "        train_pred = model.predict(X_train)\n",
    "        test_pred = model.predict(X_test)\n",
    "        X_train, X_val, y_train, y_val = self.train_val_set()\n",
    "        val_pred = model.predict(val_pred)\n",
    "        train_score, test_score, val_score = precision_recall_fscore_support(y_train, train_pred), precision_recall_fscore_support(y_test, test_pred), precision_recall_fscore_support(y_val, val_pred)\n",
    "        train_acc, test_acc, val_acc = accuracy_score(y_train, train_pred), accuracy_score(y_train, test_pred), accuracy_score(y_train, val_pred)\n",
    "        result = {'train_score': train_score, 'test_score': test_score, 'val_score': val_score, 'train_acc': train_acc, 'test_acc': test_acc, 'val_acc': val_acc}\n",
    "        return result\n",
    "\n",
    "    def rfc_train(self):\n",
    "        X_train, X_test, y_train, y_test = self.train_test_set()\n",
    "        model = LinearDiscriminantAnalysis().fit(X_train, y_train)\n",
    "        train_pred = model.predict(X_train)\n",
    "        test_pred = model.predict(X_test)\n",
    "        X_train, X_val, y_train, y_val = self.train_val_set()\n",
    "        val_pred = model.predict(val_pred)\n",
    "        train_score, test_score, val_score = precision_recall_fscore_support(y_train, train_pred), precision_recall_fscore_support(y_test, test_pred), precision_recall_fscore_support(y_val, val_pred)\n",
    "        train_acc, test_acc, val_acc = accuracy_score(y_train, train_pred), accuracy_score(y_train, test_pred), accuracy_score(y_train, val_pred)\n",
    "        result = {'train_score': train_score, 'test_score': test_score, 'val_score': val_score, 'train_acc': train_acc, 'test_acc': test_acc, 'val_acc': val_acc}\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, GradientBoostingRegressor\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "from sklearn.svm import SVC, OneClassSVM\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor, LocalOutlierFactor, NearestNeighbors\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.metrics import silhouette_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.metrics import f1_score, accuracy_score, recall_score, precision_score, precision_recall_fscore_support\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnomalyDection:\n",
    "    def __init__(self, data, target):\n",
    "        self.data = data\n",
    "        self.target = target\n",
    "\n",
    "    def train_test_set(self):\n",
    "        data = self.data\n",
    "        target = self.target\n",
    "        X = data.drop(target, axis=1)\n",
    "        y = data[target]\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        return X_train, X_test, y_train, y_test\n",
    "    \n",
    "    def train_val_set(self):\n",
    "        X_train, X_test, y_train, y_test = self.train_test_set()\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "        return X_train, X_val, y_train, y_val\n",
    "    \n",
    "    def gau_train(self):\n",
    "        # Statistical method\n",
    "        X_train, X_test, y_train, y_test = self.train_test_set()\n",
    "        gau = GaussianNB().fit(X_train, y_train)\n",
    "        # train set\n",
    "        gau_train_pred = gau.predict(X_train)\n",
    "        train_mae_score = mean_absolute_error(y_train, gau_train_pred)\n",
    "        train_mse_score = mean_squared_error(y_train, gau_train_pred)\n",
    "        # test set\n",
    "        gau_test_pred = gau.predict(X_test)\n",
    "        test_mae_score = mean_absolute_error(y_test, gau_test_pred)\n",
    "        test_mse_score = mean_squared_error(y_test, gau_test_pred)\n",
    "        # validation set\n",
    "        X_train, X_val, y_train, y_val = self.train_val_set()\n",
    "        gau_test_pred = gau.predict(X_val)\n",
    "        val_mae_score = mean_absolute_error(y_val, gau_test_pred)\n",
    "        val_mse_score = mean_squared_error(y_val, gau_test_pred)\n",
    "\n",
    "        result = {'train_mae_score': train_mae_score, 'train_mse_score': train_mse_score,\n",
    "                  'test_mae_score': test_mae_score, 'test_mse_score': test_mse_score,\n",
    "                  'val_mae_score': val_mae_score, 'val_mse_score': val_mse_score}\n",
    "        \n",
    "        return result\n",
    "\n",
    "    def gaum_train(self):\n",
    "        # Statistical method\n",
    "        X = self.data\n",
    "        gm = GaussianMixture(n_components=2, random_state=0).fit(X)\n",
    "        means = gm.means_\n",
    "        gm_pred = gm.predict(X)\n",
    "        return gm_pred\n",
    "    \n",
    "    def isf_train(self):\n",
    "        # Classification Anomaly Dectection\n",
    "        X = self.data\n",
    "        isf = IsolationForest().fit()\n",
    "        isf_pred = isf.predict(X)\n",
    "        return isf_pred\n",
    "\n",
    "    def svm_train(self):\n",
    "        # Classification Anomaly Dectection\n",
    "        X_train, X_test, y_train, y_test = self.train_test_set()\n",
    "        svm = SVC().fit(X_train, y_train)\n",
    "        # train set\n",
    "        gau_train_pred = svm.predict(X_train)\n",
    "        train_mae_score = mean_absolute_error(y_train, gau_train_pred)\n",
    "        train_mse_score = mean_squared_error(y_train, gau_train_pred)\n",
    "        # test set\n",
    "        gau_test_pred = svm.predict(X_test)\n",
    "        test_mae_score = mean_absolute_error(y_test, gau_test_pred)\n",
    "        test_mse_score = mean_squared_error(y_test, gau_test_pred)\n",
    "        # validation set\n",
    "        X_train, X_val, y_train, y_val = self.train_val_set()\n",
    "        gau_test_pred = svm.predict(X_val)\n",
    "        val_mae_score = mean_absolute_error(y_val, gau_test_pred)\n",
    "        val_mse_score = mean_squared_error(y_val, gau_test_pred)\n",
    "\n",
    "        result = {'train_mae_score': train_mae_score, 'train_mse_score': train_mse_score,\n",
    "                  'test_mae_score': test_mae_score, 'test_mse_score': test_mse_score,\n",
    "                  'val_mae_score': val_mae_score, 'val_mse_score': val_mse_score}\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def ocsvm_train(self):\n",
    "        # Classification Anomaly Dectection\n",
    "        X = self.data\n",
    "        ocsvm = OneClassSVM().fit(X)\n",
    "        pred = ocsvm.predict(X)\n",
    "        score = ocsvm.score_samples(X)\n",
    "        return pred\n",
    "    \n",
    "    def knn_train(self):\n",
    "        # Distance-based Anomaly Dectection\n",
    "        X = self.data\n",
    "        knn = NearestNeighbors().fit(X)\n",
    "        \n",
    "        return \n",
    "    \n",
    "    def lof_train(self):\n",
    "        # Density-based Anomaly Dectection\n",
    "        X = self.data\n",
    "        lof = LocalOutlierFactor().predict(X) # n_neighbors=2\n",
    "        return lof.negative_outlier_factor_()\n",
    "    \n",
    "    def kmeans_train(self):\n",
    "        # Clustering Anomaly Dectection\n",
    "        X = self.data\n",
    "        km = KMeans().fit(X)\n",
    "        score = silhouette_score(X, km.fit_predict(X))\n",
    "        return score\n",
    "    \n",
    "    def pca_train(self):\n",
    "        # Reconstruction-based Anomaly Dectection\n",
    "        X = self.data\n",
    "        n = len(X) / 2\n",
    "        pca = PCA(n_components=n, svd_solver='full').fit(X)\n",
    "        X_pca = pca.transform(X)\n",
    "        X_reconstructed = pca.inverse_transform(X_pca)\n",
    "        reconstructed_errors = np.square(X - X_reconstructed).sum(axis=1) # 음수 오차와 양수 오차가 상쇄되지 않기 위해 제곱 맟 1개의 column으로 오차 통합\n",
    "        return np.mean(reconstructed_errors) # 전체 오차 평균. ex) 6.417"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'F:\\industry\\data\\clf_data\\Test_02.csv'\n",
    "\n",
    "df = pd.read_csv(PATH)\n",
    "X = df.drop('Potability', axis=1)\n",
    "y = df['Potability']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "pca = PCA(n_components=min(X.shape[0], X.shape[1]), svd_solver='full').fit(X)\n",
    "X_pca = pca.transform(X)\n",
    "X_reconstructed = pca.inverse_transform(X_pca)\n",
    "reconstructed_errors = np.square(X - X_reconstructed).sum(axis=1) # 음수 오차와 양수 오차가 상쇄되지 않기 위해 제곱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.06342941, 0.9799947 , 1.01158725, ..., 1.05799486, 1.03393851,\n",
       "       0.9928628 ])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lof = LocalOutlierFactor().fit(X)\n",
    "-lof.negative_outlier_factor_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "lof = LocalOutlierFactor().fit(X)\n",
    "lof_result = lof.negative_outlier_factor_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "isf = IsolationForest().fit(X_train, y_train)\n",
    "isf_pred = isf.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score: 0.5115820287641594\n"
     ]
    }
   ],
   "source": [
    "y_scores = isf.decision_function(X_test)\n",
    "\n",
    "# AUC 계산\n",
    "auc_score = roc_auc_score(y_test, y_scores)\n",
    "print(\"AUC Score:\", auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1,  1])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(isf_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5300268009777417"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "km = KMeans().fit(X)\n",
    "score = silhouette_score(X, km.fit_predict(X))\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.417547501663403e-24"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(reconstructed_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnomalyDection:\n",
    "    def __init__(self, data, target):\n",
    "        self.data = data\n",
    "        self.target = target\n",
    "\n",
    "    def train_test_set(self):\n",
    "        data = self.data\n",
    "        target = self.target\n",
    "        X = data.drop(target, axis=1)\n",
    "        y = data[target]\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        return X_train, X_test, y_train, y_test\n",
    "    \n",
    "    def train_val_set(self):\n",
    "        X_train, X_test, y_train, y_test = self.train_test_set()\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "        return X_train, X_val, y_train, y_val\n",
    "\n",
    "    def unsupervised_learning(self):\n",
    "        data = self.data\n",
    "        km = KMeans()\n",
    "        km_score = silhouette_score(data, km.fit_predict(data))\n",
    "        return km_score\n",
    "    \n",
    "    def knn_train(self):\n",
    "        X_train, X_test, y_train, y_test = self.train_test_set()\n",
    "        knn = KNeighborsRegressor().fit(X_train, y_train)\n",
    "        # train\n",
    "        knn_train_pred = knn.predict(X_train)\n",
    "        knn_train_mse_score = mean_squared_error(y_train, knn_train_pred)\n",
    "        knn_train_mae_score = mean_absolute_error(y_train, knn_train_pred)\n",
    "        # test set\n",
    "        knn_test_pred = knn.predict(X_test)\n",
    "        knn_test_mae_score = mean_absolute_error(y_test, knn_test_pred)\n",
    "        knn_test_mse_score = mean_squared_error(y_test, knn_test_pred)\n",
    "        # validation set\n",
    "        X_train, X_val, y_train, y_val = self.train_val_set()\n",
    "        knn_val_pred = knn.predict(X_val)\n",
    "        knn_val_mae_score = mean_absolute_error(y_val, knn_val_pred)\n",
    "        knn_val_mse_score = mean_squared_error(y_val, knn_val_pred)\n",
    "\n",
    "        result = {'train_mse_score': knn_train_mse_score, 'train_mae_score': knn_train_mae_score,\n",
    "                  'test_mae_score': knn_test_mae_score, 'test_mse_score': knn_test_mse_score,\n",
    "                  'val_mae_score': knn_val_mae_score, 'val_mse_score': knn_val_mse_score}\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def gau_train(self):\n",
    "        X_train, X_test, y_train, y_test = self.train_test_set()\n",
    "        gau = GaussianNB().fit(X_train, y_train)\n",
    "        # train set\n",
    "        gau_train_pred = gau.predict(X_train)\n",
    "        gau_train_mae_score = mean_absolute_error(y_train, gau_train_pred)\n",
    "        gau_train_mse_score = mean_squared_error(y_train, gau_train_pred)\n",
    "        # test set\n",
    "        gau_test_pred = gau.predict(X_test)\n",
    "        gau_test_mae_score = mean_absolute_error(y_test, gau_test_pred)\n",
    "        gau_test_mse_score = mean_squared_error(y_test, gau_test_pred)\n",
    "        # validation set\n",
    "        X_train, X_val, y_train, y_val = self.train_val_set()\n",
    "        gau_test_pred = gau.predict(X_val)\n",
    "        gau_val_mae_score = mean_absolute_error(y_val, gau_test_pred)\n",
    "        gau_val_mse_score = mean_squared_error(y_val, gau_test_pred)\n",
    "\n",
    "        result = {'train_mae_score': gau_train_mae_score, 'train_mse_score': gau_train_mse_score,\n",
    "                  'test_mae_score': gau_test_mae_score, 'test_mse_score': gau_test_mse_score,\n",
    "                  'val_mae_score': gau_val_mae_score, 'val_mse_score': gau_val_mse_score}\n",
    "        \n",
    "        return result\n",
    "\n",
    "    def supervised_learning_run(self):\n",
    "        knn_result = self.knn_train()\n",
    "        gau_result = self.gau_train()\n",
    "        \n",
    "        df1 = pd.DataFrame(knn_result, index=['knn'])\n",
    "        df2 = pd.DataFrame(gau_result, index=['gau'])\n",
    "        \n",
    "        return pd.concat([df1, df2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lof_train(self):\n",
    "    X_train, X_test, y_train, y_test = self.train_test_set()\n",
    "    lof = LocalOutlierFactor().fit(X_train, y_train)\n",
    "    # train set\n",
    "    lof_train_pred = lof.predict(X_train)\n",
    "    lof_train_mae_score = mean_absolute_error(y_train, lof_train_pred)\n",
    "    lof_train_mse_score = mean_squared_error(y_train, lof_train_pred)\n",
    "    # test set\n",
    "    lof_test_pred = lof.predict(X_test)\n",
    "    lof_test_mae_score = mean_absolute_error(y_test, lof_test_pred)\n",
    "    lof_test_mse_score = mean_squared_error(y_test, lof_test_pred)\n",
    "    # validation set\n",
    "    X_train, X_val, y_train, y_val = self.train_val_set()\n",
    "    lof_test_pred = lof.predict(X_val)\n",
    "    lof_val_mae_score = mean_absolute_error(y_val, lof_test_pred)\n",
    "    lof_val_mse_score = mean_squared_error(y_val, lof_test_pred)\n",
    "\n",
    "    result = {'train_mae_score': lof_train_mae_score, 'train_mse_score': lof_train_mse_score,\n",
    "                'test_mae_score': lof_test_mae_score, 'test_mse_score': lof_test_mse_score,\n",
    "                'val_mae_score': lof_val_mae_score, 'val_mse_score': lof_val_mse_score}\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'F:\\industry\\data\\clf_data\\Test_02.csv'\n",
    "\n",
    "df = pd.read_csv(PATH)\n",
    "X = df.drop('Potability', axis=1)\n",
    "y = df['Potability']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = LocalOutlierFactor().fit(X, y)\n",
    "y_pred = test.fit_predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.06342941, -0.9799947 , -1.01158725, ..., -1.05799486,\n",
       "       -1.03393851, -0.9928628 ])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.negative_outlier_factor_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AnomalyDection(df, 'Potability')\n",
    "supervised_result = model.supervised_learning_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_mse_score</th>\n",
       "      <th>train_mae_score</th>\n",
       "      <th>test_mae_score</th>\n",
       "      <th>test_mse_score</th>\n",
       "      <th>val_mae_score</th>\n",
       "      <th>val_mse_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>knn</th>\n",
       "      <td>0.195327</td>\n",
       "      <td>0.392259</td>\n",
       "      <td>0.493820</td>\n",
       "      <td>0.296517</td>\n",
       "      <td>0.397895</td>\n",
       "      <td>0.199439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gau</th>\n",
       "      <td>0.427868</td>\n",
       "      <td>0.427868</td>\n",
       "      <td>0.483146</td>\n",
       "      <td>0.483146</td>\n",
       "      <td>0.407018</td>\n",
       "      <td>0.407018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     train_mse_score  train_mae_score  test_mae_score  test_mse_score  \\\n",
       "knn         0.195327         0.392259        0.493820        0.296517   \n",
       "gau         0.427868         0.427868        0.483146        0.483146   \n",
       "\n",
       "     val_mae_score  val_mse_score  \n",
       "knn       0.397895       0.199439  \n",
       "gau       0.407018       0.407018  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "supervised_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'aaa'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df1 = pd.DataFrame({'a': [1, 2, 3], 'b': [4, 5, 6]})\n",
    "df2 = pd.DataFrame({'a': [1, 2, 3], 'b': [4, 5, 6]})\n",
    "\n",
    "concat_df = pd.concat([df1, df2])\n",
    "concat_df.index=['1', 'a', 'a',  'a', 'a', 'a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a  b\n",
       "1  1  4\n",
       "a  2  5\n",
       "a  3  6\n",
       "a  1  4\n",
       "a  2  5\n",
       "a  3  6"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
